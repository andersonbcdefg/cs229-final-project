{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets of tweets\n",
    "Before feature extraction, we do the train-dev-test split, so that these datasets are constant across feature extraction methods. For binary classification, the positive examples come from the Russian troll tweets dataset. Negative examples are a combination of a sentiment dataset, and a dataset of tweets from Republican and Democratic politicians. (We want to make sure that there are negative examples that still have a \"political\" orientation, since our goal is to tell troll tweets from real tweets, rather than political from non-political.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_examples = pd.read_csv(\"data/preprocessed-text/preprocessed-troll-tweets.csv\")\n",
    "neg_sentiment_examples = pd.read_csv(\"data/preprocessed-text/sentiment-preprocessed.csv\",\n",
    "                                    encoding=\"latin\").rename(columns={\"account_type\":\"account_category\"})\n",
    "neg_political_examples = pd.read_csv(\n",
    "    \"data/preprocessed-text/big-political-preprocessed.csv\").rename(columns={\n",
    "    \"account_type\":\"account_category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970780, 1600498, 1243370)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_examples), len(neg_sentiment_examples), len(neg_political_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'account_category', 'troll'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sentiment_examples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 229\n",
    "combined = pd.concat([\n",
    "    pos_examples,\n",
    "    neg_sentiment_examples.sample(n=1000000, random_state=random_state),\n",
    "    neg_political_examples.sample(n=1000000, random_state=random_state)\n",
    "]).sample(frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>account_category</th>\n",
       "      <th>troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@BilgeEbiri really nails why many villains in...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton, Trump lead 2016 delegate race https:/...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @the_intercept: How our reporter @JuanMThom...</td>\n",
       "      <td>LeftTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruz, Colbert debate Reagan, gay marriage  #en...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'@420omnivore @leyalouisee May be this girl wi...</td>\n",
       "      <td>LeftTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>More to Jamaica than 'anti-gay Gestapos': Man ...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Darkness cannot drive out darkness; only light...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm thrilled to be here @ #CBCFALC2012 hosting...</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nearly all men can stand adversity, but if you...</td>\n",
       "      <td>LeftTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>‘Reprehensible’ fondling of 7-year-old girl by...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @margmiley: @sethmoulton @GOP Grateful that...</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Over 23 percent of Florida’s workforce will be...</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#mar RT BelindaBee13: You Keith are crazy, fou...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Threat forces flight to evacuate at JFK Airpor...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DEMENTED House Democrat Vows to “ELIMINATE” Tr...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is very happy</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Police: Man Smoking Heroin In Car Tried To Run...</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wells Fargo cheated customers &amp;amp; until it l...</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The financial crisis begin ten years ago today...</td>\n",
       "      <td>RightTroll</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@aristofontes we all know very well that our s...</td>\n",
       "      <td>NotTroll</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content account_category  troll\n",
       "0   .@BilgeEbiri really nails why many villains in...       RightTroll   True\n",
       "1   Clinton, Trump lead 2016 delegate race https:/...         NewsFeed   True\n",
       "2   RT @the_intercept: How our reporter @JuanMThom...        LeftTroll   True\n",
       "3   Cruz, Colbert debate Reagan, gay marriage  #en...         NewsFeed   True\n",
       "4   '@420omnivore @leyalouisee May be this girl wi...        LeftTroll   True\n",
       "5   More to Jamaica than 'anti-gay Gestapos': Man ...         NewsFeed   True\n",
       "6   Darkness cannot drive out darkness; only light...       RightTroll   True\n",
       "7   I'm thrilled to be here @ #CBCFALC2012 hosting...         NotTroll  False\n",
       "8   Nearly all men can stand adversity, but if you...        LeftTroll   True\n",
       "9   ‘Reprehensible’ fondling of 7-year-old girl by...         NewsFeed   True\n",
       "10  RT @margmiley: @sethmoulton @GOP Grateful that...         NotTroll  False\n",
       "11  Over 23 percent of Florida’s workforce will be...         NotTroll  False\n",
       "12  #mar RT BelindaBee13: You Keith are crazy, fou...       RightTroll   True\n",
       "13  Threat forces flight to evacuate at JFK Airpor...         NewsFeed   True\n",
       "14  DEMENTED House Democrat Vows to “ELIMINATE” Tr...       RightTroll   True\n",
       "15                                      is very happy         NotTroll  False\n",
       "16  Police: Man Smoking Heroin In Car Tried To Run...         NewsFeed   True\n",
       "17  Wells Fargo cheated customers &amp; until it l...         NotTroll  False\n",
       "18  The financial crisis begin ten years ago today...       RightTroll   True\n",
       "19  @aristofontes we all know very well that our s...         NotTroll  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)\n",
    "combined.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"troll\": combined.groupby(\"account_category\").count(), \n",
    "    \"categories\": combined.groupby(\"troll\").count()\n",
    "}\n",
    "pickle.dump(metadata, open(\"data/preprocessed-text/combined-metadata.pickle\", \"wb+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff, dev_cutoff = int(len(combined) * 0.7), int(len(combined) * 0.85)\n",
    "train_tweets = combined.iloc[:train_cutoff,:]\n",
    "dev_tweets = combined.iloc[train_cutoff:dev_cutoff,:]\n",
    "test_tweets = combined.iloc[dev_cutoff:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets.to_csv(\"data/preprocessed-text/train_tweets.csv\", index=False)\n",
    "dev_tweets.to_csv(\"data/preprocessed-text/dev_tweets.csv\", index=False)\n",
    "test_tweets.to_csv(\"data/preprocessed-text/test_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT features\n",
    "Take these raw tweets for train, dev, and test sets and use pretrained BERT to create features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = pd.read_csv(\"data/preprocessed-text/train_tweets.csv\",\n",
    "                          dtype={'content':'string', 'account_category':'string', 'troll':'boolean'})\n",
    "dev_tweets = pd.read_csv(\"data/preprocessed-text/dev_tweets.csv\",\n",
    "                          dtype={'content':'string', 'account_category':'string', 'troll':'boolean'})\n",
    "test_tweets = pd.read_csv(\"data/preprocessed-text/test_tweets.csv\",\n",
    "                          dtype={'content':'string', 'account_category':'string', 'troll':'boolean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# feature_extractor = pipeline('feature-extraction', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Pandas Series of tweets.\n",
    "# Output: DataFrame of features where each column is a feature,\n",
    "#         and each row is a tweet.\n",
    "def bert_featurize(tweets, model, tokenizer):\n",
    "    encoded = tweets.apply(lambda t: tokenizer.encode(t))\n",
    "    max_len = np.max([len(t) for t in encoded.tolist()])\n",
    "    padded = encoded.apply(lambda t: np.array(t + [0] * (max_len - len(t))))\n",
    "    model_input = torch.tensor(np.vstack(padded.values))\n",
    "    attention_mask = torch.tensor(np.where(model_input == 0, 0, 1))\n",
    "    with torch.no_grad():\n",
    "        output = model(model_input, attention_mask=attention_mask)\n",
    "    return pd.DataFrame(output[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Pandas DataFrame including \"content\" column for tweets.\n",
    "# Output: Same DataFrame with BERT features added in new columns.\n",
    "def bert_featurize_df(df, model, tokenizer, batch_size, outfile):\n",
    "    for idx in tqdm(range(0, len(df), batch_size)):\n",
    "        chunk = df.iloc[idx:idx + batch_size, :]\n",
    "        bert_features = bert_featurize(chunk[\"content\"], model, tokenizer)\n",
    "        combined = chunk.reset_index(drop=True).join(bert_features.reset_index(drop=True))\n",
    "        combined.to_csv(outfile, mode='a', index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48c2ec3bb7547909c75e2ad80f50af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# simple test\n",
    "bert_featurize_df(train_tweets[:200], model, tokenizer, batch_size=10, outfile=\"data/transformer-binary/tiny.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller datasets, taking a subsample of each of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bert_featurize_df(train_tweets[:100000], model, tokenizer, batch_size=50, \n",
    "                  outfile=\"data/transformer-binary/bert_train_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_featurize_df(dev_tweets[:15000], model, tokenizer, batch_size=50,\n",
    "                 outfile=\"data/transformer-binary/dev_bert_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_featurize_df(test_tweets[:15000], model, tokenizer, batch_size=50,\n",
    "                 outfile=\"data/transformer-binary/test_bert_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger datasets, using the entirety of each split. (Takes a *long* time to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cada64e2894dcab6638fed8b41d2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=55060.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_featurize_df(train_tweets.dropna()[1403050:], model, tokenizer, batch_size=25,\n",
    "                 outfile=\"data/transformer-binary/train_bert_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_bert_large = bert_featurize_df(dev_tweets, model, tokenizer, batch_size=100)\n",
    "dev_bert_large.to_csv(\"data/transformer-binary/dev_bert_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert_large = bert_featurize_df(test_tweets, model, tokenizer, batch_size=100)\n",
    "test_bert_large.to_csv(\"data/transformer-binary/test_bert_large.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Bag of Words\" Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def create_vocab(tweets):\n",
    "    word_counts = default_dict(int)\n",
    "    # Use training data to construct vocabulary\n",
    "    for row_idx in len(tweets):\n",
    "        tweet = tweets['content'].iloc[row_idx] \n",
    "        words = re.sub(r'[^\\w\\s#]', '', tweet).lower().strip().split(\" \")\n",
    "        for word in words:\n",
    "            word_counts[word] += 1\n",
    "\n",
    "    # Filter out words that occur more than 0.75x the number of tweets, or less than 100 times.\n",
    "    filtered = {k:v for k, v in word_counts.items() if v >= 100 and v < len(tweets) * 0.75}\n",
    "    return {word: i for i, word in enumerate(filtered)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_arr(tweet, vocab):\n",
    "    words = re.sub(r'[^\\w\\s#]', '', tweet).lower().strip().split(\" \")\n",
    "    idxs = [vocab[word] for word in words]\n",
    "    arr = np.zeros((vocab,))\n",
    "    arr[[idxs]] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_featurize(df, vocab):\n",
    "    tweets = df.content\n",
    "    arrs = tweets.apply(lambda tweet: tweet_to_arr(tweet, vocab))\n",
    "    features = np.vstack(arrs.values)\n",
    "    return df.reset_index(drop=True).join(pd.DataFrame(features).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/.pyenv/versions/3.8.5/envs/data-analysis/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1403050"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(\"data/transformer-binary/train_bert_large.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
